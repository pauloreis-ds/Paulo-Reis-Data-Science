{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine with Cancer data\n",
    "\n",
    "## Agenda \n",
    "            Quick Exploration\n",
    "        1 - Training Model\n",
    "            Training and test subsets Short Exemple - just see what is happening \n",
    "        2 - Implementing a SVM\n",
    "        3 - Predictions vs Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine Learning\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This time we'll be using a dataset that sklearn provides us**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      " ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "cancer = datasets.load_breast_cancer()\n",
    "\n",
    "print('Features:\\n', cancer.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'], dtype='<U9')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Labels: ', cancer.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' It's quite big to print here, but after analyzing I think it's a dictionary or some type similar '''\n",
    "# cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "target\n",
      "frame\n",
      "target_names\n",
      "DESCR\n",
      "feature_names\n",
      "filename\n"
     ]
    }
   ],
   "source": [
    "for key in cancer:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_X = cancer.data \n",
    "labels_y = cancer.target  \n",
    "\n",
    "\n",
    "'''  Splitting the features and labels into random train and test subsets '''\n",
    "features_X_train, features_X_test, labels_y_train, labels_y_test = sklearn.model_selection.train_test_split(features_X,\n",
    "                                                                                                            labels_y,\n",
    "                                                                                                            test_size=0.2)\n",
    "# 0.2 (20%) of the data is being allocated as test data while the other 90% is being treated as training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[features_X_train and labels_y_train] will be used to train our model**<br>\n",
    "(and make the machine learn)\n",
    "\n",
    "**[features_X_test and labels_y_test] will be used to test the accuracy of our model**<br>\n",
    "(ratio of number of correct predictions to the total number of input samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### |----- _Training and test subsets Short Exemple - just see what is happening_ -----|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      " [[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "y:\n",
      " [0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "''' Here's values for X and y '''\n",
    "X , y = np.arange(10).reshape((5, 2)), np.arange(5)\n",
    "print('X:\\n',X)\n",
    "print('y:\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random X_train values:\n",
      " [[0 1]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "\n",
      "Random y_train values:\n",
      " [0 2 3 4]\n",
      "\n",
      "Random X_test values:\n",
      " [[2 3]]\n",
      "\n",
      "Random y_test values:\n",
      " [1]\n"
     ]
    }
   ],
   "source": [
    "''' What we are doing '''\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "print('Random X_train values:\\n',X_train)\n",
    "print('\\nRandom y_train values:\\n',y_train)\n",
    "print('\\nRandom X_test values:\\n',X_test)\n",
    "print('\\nRandom y_test values:\\n',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### |----- _End of exemple [ \\o/ ]_ -----|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_X_train:\n",
      "\n",
      " [[1.611e+01 1.805e+01 1.051e+02 8.130e+02 9.721e-02 1.137e-01 9.447e-02\n",
      "  5.943e-02 1.861e-01 6.248e-02 7.049e-01 1.332e+00 4.533e+00 7.408e+01\n",
      "  6.770e-03 1.938e-02 3.067e-02 1.167e-02 1.875e-02 3.434e-03 1.992e+01\n",
      "  2.527e+01 1.290e+02 1.233e+03 1.314e-01 2.236e-01 2.802e-01 1.216e-01\n",
      "  2.792e-01 8.158e-02]\n",
      " [8.597e+00 1.860e+01 5.409e+01 2.212e+02 1.074e-01 5.847e-02 0.000e+00\n",
      "  0.000e+00 2.163e-01 7.359e-02 3.368e-01 2.777e+00 2.222e+00 1.781e+01\n",
      "  2.075e-02 1.403e-02 0.000e+00 0.000e+00 6.146e-02 6.820e-03 8.952e+00\n",
      "  2.244e+01 5.665e+01 2.401e+02 1.347e-01 7.767e-02 0.000e+00 0.000e+00\n",
      "  3.142e-01 8.116e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 1.203e+03 1.096e-01 1.599e-01 1.974e-01\n",
      "  1.279e-01 2.069e-01 5.999e-02 7.456e-01 7.869e-01 4.585e+00 9.403e+01\n",
      "  6.150e-03 4.006e-02 3.832e-02 2.058e-02 2.250e-02 4.571e-03 2.357e+01\n",
      "  2.553e+01 1.525e+02 1.709e+03 1.444e-01 4.245e-01 4.504e-01 2.430e-01\n",
      "  3.613e-01 8.758e-02]\n",
      " [1.571e+01 1.393e+01 1.020e+02 7.617e+02 9.462e-02 9.462e-02 7.135e-02\n",
      "  5.933e-02 1.816e-01 5.723e-02 3.117e-01 8.155e-01 1.972e+00 2.794e+01\n",
      "  5.217e-03 1.515e-02 1.678e-02 1.268e-02 1.669e-02 2.330e-03 1.750e+01\n",
      "  1.925e+01 1.143e+02 9.228e+02 1.223e-01 1.949e-01 1.709e-01 1.374e-01\n",
      "  2.723e-01 7.071e-02]\n",
      " [1.150e+01 1.845e+01 7.328e+01 4.074e+02 9.345e-02 5.991e-02 2.638e-02\n",
      "  2.069e-02 1.834e-01 5.934e-02 3.927e-01 8.429e-01 2.684e+00 2.699e+01\n",
      "  6.380e-03 1.065e-02 1.245e-02 9.175e-03 2.292e-02 1.461e-03 1.297e+01\n",
      "  2.246e+01 8.312e+01 5.089e+02 1.183e-01 1.049e-01 8.105e-02 6.544e-02\n",
      "  2.740e-01 6.487e-02]] \n",
      "\n",
      "labels_y_train:\n",
      "\n",
      " [0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Part of our data\n",
    "print('features_X_train:\\n\\n',features_X_train[:5],'\\n\\nlabels_y_train:\\n\\n', labels_y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this later to instead of looking at labels like those above: [0 1 0 1 1]\n",
    "# We'll look at them like this:\n",
    "classes = ['malignant', 'benign']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "# Creating a SVC() instance, so we can use its methods to classify\n",
    "svm_classifier = svm.SVC()\n",
    "\n",
    "# Training the model\n",
    "svm_classifier.fit(features_X_train, labels_y_train)\n",
    "\n",
    "\n",
    "# Comparing the predictions with the actual data to find out the accuracy\n",
    "labels_y_predictions = svm_classifier.predict(features_X_test)\n",
    "accuracy = metrics.accuracy_score(labels_y_test, labels_y_predictions)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Predictions vs Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.106e+01 1.483e+01 7.031e+01 3.782e+02 7.741e-02 4.768e-02 2.712e-02\n",
      " 7.246e-03 1.535e-01 6.214e-02 1.855e-01 6.881e-01 1.263e+00 1.298e+01\n",
      " 4.259e-03 1.469e-02 1.940e-02 4.168e-03 1.191e-02 3.537e-03 1.268e+01\n",
      " 2.035e+01 8.079e+01 4.967e+02 1.120e-01 1.879e-01 2.079e-01 5.556e-02\n",
      " 2.590e-01 9.158e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.205e+01 2.272e+01 7.875e+01 4.478e+02 6.935e-02 1.073e-01 7.943e-02\n",
      " 2.978e-02 1.203e-01 6.659e-02 1.194e-01 1.434e+00 1.778e+00 9.549e+00\n",
      " 5.042e-03 4.560e-02 4.305e-02 1.667e-02 2.470e-02 7.358e-03 1.257e+01\n",
      " 2.871e+01 8.736e+01 4.884e+02 8.799e-02 3.214e-01 2.912e-01 1.092e-01\n",
      " 2.191e-01 9.349e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.133e+01 1.416e+01 7.179e+01 3.966e+02 9.379e-02 3.872e-02 1.487e-03\n",
      " 3.333e-03 1.954e-01 5.821e-02 2.375e-01 1.280e+00 1.565e+00 1.709e+01\n",
      " 8.426e-03 8.998e-03 1.487e-03 3.333e-03 2.358e-02 1.627e-03 1.220e+01\n",
      " 1.899e+01 7.737e+01 4.580e+02 1.259e-01 7.348e-02 4.955e-03 1.111e-02\n",
      " 2.758e-01 6.386e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.236e+01 2.180e+01 7.978e+01 4.661e+02 8.772e-02 9.445e-02 6.015e-02\n",
      " 3.745e-02 1.930e-01 6.404e-02 2.978e-01 1.502e+00 2.203e+00 2.095e+01\n",
      " 7.112e-03 2.493e-02 2.703e-02 1.293e-02 1.958e-02 4.463e-03 1.383e+01\n",
      " 3.050e+01 9.146e+01 5.747e+02 1.304e-01 2.463e-01 2.434e-01 1.205e-01\n",
      " 2.972e-01 9.261e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.464e+01 1.685e+01 9.421e+01 6.660e+02 8.641e-02 6.698e-02 5.192e-02\n",
      " 2.791e-02 1.409e-01 5.355e-02 2.204e-01 1.006e+00 1.471e+00 1.998e+01\n",
      " 3.535e-03 1.393e-02 1.800e-02 6.144e-03 1.254e-02 1.219e-03 1.646e+01\n",
      " 2.544e+01 1.060e+02 8.310e+02 1.142e-01 2.070e-01 2.437e-01 7.828e-02\n",
      " 2.455e-01 6.596e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.222e+01 2.004e+01 7.947e+01 4.531e+02 1.096e-01 1.152e-01 8.175e-02\n",
      " 2.166e-02 2.124e-01 6.894e-02 1.811e-01 7.959e-01 9.857e-01 1.258e+01\n",
      " 6.272e-03 2.198e-02 3.966e-02 9.894e-03 1.320e-02 3.813e-03 1.316e+01\n",
      " 2.417e+01 8.513e+01 5.153e+02 1.402e-01 2.315e-01 3.535e-01 8.088e-02\n",
      " 2.709e-01 8.839e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  0 --> malignant\n",
      "\n",
      "Input Data:\n",
      " [1.865e+01 1.760e+01 1.237e+02 1.076e+03 1.099e-01 1.686e-01 1.974e-01\n",
      " 1.009e-01 1.907e-01 6.049e-02 6.289e-01 6.633e-01 4.293e+00 7.156e+01\n",
      " 6.294e-03 3.994e-02 5.554e-02 1.695e-02 2.428e-02 3.535e-03 2.282e+01\n",
      " 2.132e+01 1.506e+02 1.567e+03 1.679e-01 5.090e-01 7.345e-01 2.378e-01\n",
      " 3.799e-01 9.185e-02]\n",
      "\n",
      "Actual value 0   -->    malignant\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.170e+01 1.911e+01 7.433e+01 4.187e+02 8.814e-02 5.253e-02 1.583e-02\n",
      " 1.148e-02 1.936e-01 6.128e-02 1.601e-01 1.430e+00 1.109e+00 1.128e+01\n",
      " 6.064e-03 9.110e-03 1.042e-02 7.638e-03 2.349e-02 1.661e-03 1.261e+01\n",
      " 2.655e+01 8.092e+01 4.831e+02 1.223e-01 1.087e-01 7.915e-02 5.741e-02\n",
      " 3.487e-01 6.958e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [9.504e+00 1.244e+01 6.034e+01 2.739e+02 1.024e-01 6.492e-02 2.956e-02\n",
      " 2.076e-02 1.815e-01 6.905e-02 2.773e-01 9.768e-01 1.909e+00 1.570e+01\n",
      " 9.606e-03 1.432e-02 1.985e-02 1.421e-02 2.027e-02 2.968e-03 1.023e+01\n",
      " 1.566e+01 6.513e+01 3.149e+02 1.324e-01 1.148e-01 8.867e-02 6.227e-02\n",
      " 2.450e-01 7.773e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  1 --> benign\n",
      "\n",
      "Input Data:\n",
      " [1.402e+01 1.566e+01 8.959e+01 6.065e+02 7.966e-02 5.581e-02 2.087e-02\n",
      " 2.652e-02 1.589e-01 5.586e-02 2.142e-01 6.549e-01 1.606e+00 1.925e+01\n",
      " 4.837e-03 9.238e-03 9.213e-03 1.076e-02 1.171e-02 2.104e-03 1.491e+01\n",
      " 1.931e+01 9.653e+01 6.889e+02 1.034e-01 1.017e-01 6.260e-02 8.216e-02\n",
      " 2.136e-01 6.710e-02]\n",
      "\n",
      "Actual value 1   -->    benign\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n",
      "Predicted value:  0 --> malignant\n",
      "\n",
      "Input Data:\n",
      " [1.916e+01 2.660e+01 1.262e+02 1.138e+03 1.020e-01 1.453e-01 1.921e-01\n",
      " 9.664e-02 1.902e-01 6.220e-02 6.361e-01 1.001e+00 4.321e+00 6.965e+01\n",
      " 7.392e-03 2.449e-02 3.988e-02 1.293e-02 1.435e-02 3.446e-03 2.372e+01\n",
      " 3.590e+01 1.598e+02 1.724e+03 1.782e-01 3.841e-01 5.754e-01 1.872e-01\n",
      " 3.258e-01 9.720e-02]\n",
      "\n",
      "Actual value 0   -->    malignant\n",
      "-------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As I said, doing this, We'll get not just the number(0 or 1) but its actual meaning\n",
    "classes = ['malignant', 'benign']\n",
    "\n",
    "predicted_values = svm_classifier.predict(features_X_test)\n",
    "\n",
    "break_point = 0 # I don't want to print the whole dataset\n",
    "for value in range(len(features_X_test)):\n",
    "    print('Predicted value: ', predicted_values[value], '-->', classes[predicted_values[value]])\n",
    "    print('\\nInput Data:\\n', features_X_test[value])\n",
    "    print('\\nActual value', labels_y_test[value], '  -->   ', classes[labels_y_test[value]])\n",
    "    print('-'*50,'\\n\\n')\n",
    "    if break_point == 10: break\n",
    "    break_point += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
