{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a basic code visualization made to help you to understand each step in a machine learning code. Of course there are a lot more steps we could add, but eventually you'll learn about them.\n",
    "\n",
    "# How Do We Actually machine.learning(learn=True) Things?\n",
    "\n",
    "**Let's see this process in a pseudocode**\n",
    "\n",
    "**First, We load the data into memory:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = function_to.load_data(\"file with data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**...and after we prepare the data ([Exploratory Data Analysis](https://github.com/pauloreis-ds/Machine-Learning-ROADMAP/tree/master/5%20-%20Data%20Preparation/0%20-%20Exploratory%20Data%20Analysis%20(EDA)),  [Data Preprocessing](https://github.com/pauloreis-ds/Machine-Learning-ROADMAP/tree/master/5%20-%20Data%20Preparation/1%20-%20Data%20Preprocessing)...) we can apply machine learning to it:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing only what is necessary\n",
    "\n",
    "from ML_library.helpful_methods import train_test_split\n",
    "from ML_library.selecting_model import YourModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - You [split the data](https://github.com/pauloreis-ds/Machine-Learning-ROADMAP/tree/master/5%20-%20Data%20Preparation/2%20-%20Data%20Splitting) into training and test data. In this case We are using a method from the \"machine learning library\" to do that for us, but you could do it in a different way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['column to be X features'], data['column to be y labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 - You create an instance of  YourModel object, so you can use its methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YourModel() object type\n"
     ]
    }
   ],
   "source": [
    "model = YourModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 - Now you use the object methods to solve your problem and predict or classify whatever you want. And you do that by training the model (aka fitting model ([.fit](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression.fit))), avaluating it ([.score](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression.score)), and more...**\n",
    "\n",
    "> .fit() .score() - These methods kind of \"vary\" from model to model, for example, you may see [.fit_transform()](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html?highlight=knn#sklearn.impute.KNNImputer.fit_transform) or [.fit_predict()](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM.fit_predict), but the basis is the same.\n",
    "\n",
    "**The model will take care of figuring out the (mathematical) relationship between the data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.training_the_algorithm(X_train, y_train, any_other_parameter_you_may_use_to_tune_the_model = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally, We use the _test data_ (which model has never seen/touched) to see if it has found the function that better represents the interaction/relationship between the data and how good this model is:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "print('Score: ', model.avaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this point, We think if model's \"accuracy\" is good enough to be used or if We need to tune our model by changing some parameters in some methods or perhaps working more on feature engineering or data preprocessing...**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
