{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping - First steps\n",
    "\n",
    "    Examining the New York Times article: Trump’s Lies. \n",
    "    When converting it into a dataset, you can think of each lie as a \"record\" with four fields:\n",
    "        The date of the lie.\n",
    "        The lie itself (as a quotation).\n",
    "        The writer's brief explanation of why it was a lie.\n",
    "        The URL of an article that substantiates the claim that it was a lie.\n",
    "\n",
    "Video that helped me: https://www.youtube.com/playlist?list=PL5-da3qGB5IDbOi0g5WFh1YPDNzXw4LNL\n",
    "\n",
    "## Agenda\n",
    "    1 - Reading the web page into Python\n",
    "    2 - Parsing the HTML using Beautiful Soup\n",
    "    3 - Extracting the components \n",
    "        3.1 Extracting the date\n",
    "        3.2 Extracting the lie\n",
    "        3.3 Extracting the explanation\n",
    "        3.4 Extracting the URL\n",
    "    4 - Recap: Beautiful Soup methods and attributes\n",
    "    5 - Building the dataset\n",
    "    6 - Applying a tabular data structure\n",
    "    7 - Exporting the dataset to a CSV file\n",
    "    8 - Summary: 16 lines of Python code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the web page into Python\n",
    "    The first thing we need to do is to read the HTML into Python, which we'll\n",
    "    do using the requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if (gt IE 9)|!(IE)]> <!--><html lang=\"en\" class=\"no-js page-interactive section-opinion page-theme-standard tone-opinion page-interactive-default limit-small layout-xlarge app-interactive\" itemid=\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\" itemtype=\"http://schema.org/NewsArticle\" itemscope xmlns:og=\"http://opengraphprotocol.org/schema/\"><!--<![endif]-->\n",
      "<!--[if IE 9]> <html lang=\"en\" class=\"no-js ie9 lt-ie10 page-interactive section-opinion page\n"
     ]
    }
   ],
   "source": [
    "# print the first 500 characters of the HTML\n",
    "\n",
    "print(r.text[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Parsing the HTML using Beautiful Soup\n",
    "    We're going to parse the HTML into a BeautifulSoup() object called soup.\n",
    "    This object has attributes and methods we'll use to scrape the web page.\n",
    "    \n",
    "    In other words, BeautifulSoup is reading the HTML and making sense of its structure.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each record We want has the following format:\n",
    "    \n",
    "    This is the pattern that allows us to build our dataset:\n",
    "    \n",
    "    <span class=\"short-desc\"><strong> DATE </strong> LIE <span class=\"short-truth\"><a href=\"URL\"> EXPLANATION </a></span></span>\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BeautifulSoup will find all the records\n",
    "'''\n",
    "    It is basically getting all of this part of the HTML pattern <span class=\"short-desc\">\n",
    "'''\n",
    "\n",
    "results = soup.find_all('span', attrs={'class':'short-desc'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ps: results acts like a python list\n",
    "''' \n",
    "    180 means there are 180 \"soup objects\", so to speak.  \n",
    "    \n",
    "    180 <span> tags with the attribute class=\"short-desc\"\n",
    "'''\n",
    "\n",
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>,\n",
       " <span class=\"short-desc\"><strong>Jan. 21 </strong>“A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.” <span class=\"short-truth\"><a href=\"http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/\" target=\"_blank\">(Trump was on the cover 11 times and Nixon appeared 55 times.)</a></span></span>,\n",
       " <span class=\"short-desc\"><strong>Jan. 23 </strong>“Between 3 million and 5 million illegal votes caused me to lose the popular vote.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html\" target=\"_blank\">(There's no evidence of illegal voting.)</a></span></span>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>\n",
      "\n",
      "<span class=\"short-desc\"><strong>Jan. 21 </strong>“A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.” <span class=\"short-truth\"><a href=\"http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/\" target=\"_blank\">(Trump was on the cover 11 times and Nixon appeared 55 times.)</a></span></span>\n",
      "\n",
      "<span class=\"short-desc\"><strong>Jan. 23 </strong>“Between 3 million and 5 million illegal votes caused me to lose the popular vote.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html\" target=\"_blank\">(There's no evidence of illegal voting.)</a></span></span>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Notice the similar structure\n",
    "\n",
    "for content in results[0:3]:\n",
    "    print(content)\n",
    "    print() # space   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Nov. 11 </strong>“I'd rather have him  – you know, work with him on the Ukraine than standing and arguing about whether or not  – because that whole thing was set up by the Democrats.” <span class=\"short-truth\"><a href=\"https://www.nytimes.com/interactive/2017/12/10/us/politics/trump-and-russia.html\" target=\"_blank\">(There is no evidence that Democrats \"set up\" Russian interference in the election.)</a></span></span>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The last record\n",
    "\n",
    "results[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Extracting the components \n",
    "    \n",
    "    We have now collected all 116 of the records, but we still need to separate\n",
    "    each record into its four components (date, lie, explanation, and URL) in\n",
    "    order to give the dataset some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the date\n",
    "\n",
    "    Although first_result may look like a Python string, you'll notice that there \n",
    "    are no quote marks around it. Instead, it's another special BeautifulSoup() \n",
    "    object (called a \"Tag\") that has specific methods and attributes.\n",
    "\n",
    "    In order to locate the date, we can use its .find() method to find a single tag\n",
    "    that matches a specific pattern, in contrast to the find_all() method we used \n",
    "    above to find all tags that match a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result = results[0]\n",
    "first_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<strong>Jan. 21 </strong>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    From the components above, We are getting this part: \n",
    "    \n",
    "    <span class=\"short-desc\">\n",
    "    \n",
    "    \n",
    "    \n",
    "    \\(*O*)/    <strong>Jan. 21 </strong>       \\(*O*)/\n",
    "    \n",
    "    \n",
    "    \n",
    "    “I wasn't a fan of Iraq.\n",
    "    I didn't want to go into Iraq.” <span class=\"short-truth\">\n",
    "    <a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he\n",
    "    -supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before\n",
    "    he was against it.)</a></span></span>\n",
    "'''\n",
    "\n",
    "first_result.find('strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan. 21\\xa0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Since we want to extract the text between the opening and closing tags, \n",
    "    we can access its text attribute (with .text), which does in fact return \n",
    "    a regular Python string\n",
    "'''\n",
    "\n",
    "first_result.find('strong').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is \\xa0? You don't actually need to know this, but it's called an \"escape sequence\" that represents the *&nbsp* character we saw earlier in the HTML source.\n",
    "\n",
    "However, you do need to know that an **escape sequence represents a single character** within a string. Let's slice it off from the end of the string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan. 21'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.find('strong').text[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan. 21, 2017'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Finally, we're going to add the year, since we don't want our dataset to include ambiguous dates:\n",
    "'''\n",
    "# Save this in your memory. We'll use it later, since this is the code that return to us\n",
    "# one of the components we want to put in the dataset.\n",
    "\n",
    "first_result.find('strong').text[0:-1] + ', 2017'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the lie\n",
    "    Our goal is to extract the two sentences about Iraq. Unfortunately, \n",
    "    there isn't a pair of opening and closing tags that starts immediately \n",
    "    before the them and ends immediately after the them. Therefore, we're going\n",
    "    to have to use a different technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<strong>Jan. 21 </strong>,\n",
       " \"“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \",\n",
       " <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    The first_result Tag has a \"contents\" attribute, which returns a Python list \n",
    "    containing its \"children\" (Tags and strings that are nested within a Tag)\n",
    "\n",
    "    We can slice this list to extract the second element:\n",
    "'''\n",
    "\n",
    "first_result.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHILD INDEX [ 0 ]\n",
      "<strong>Jan. 21 </strong>\n",
      "\n",
      "\n",
      "\n",
      "CHILD INDEX [ 1 ]\n",
      "“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \n",
      "\n",
      "\n",
      "\n",
      "CHILD INDEX [ 2 ]\n",
      "<span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Nth = 0\n",
    "for child in first_result.contents:\n",
    "    print('CHILD INDEX [', Nth,']')\n",
    "    print(child)\n",
    "    print('\\n\\n')\n",
    "    Nth += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"“I wasn't a fan of Iraq. I didn't want to go into Iraq.” \""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    As what we want is the index number 1, we can just\n",
    "'''\n",
    "\n",
    "first_result.contents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I wasn't a fan of Iraq. I didn't want to go into Iraq.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    And now we slice off the quotation marks:\n",
    "'''\n",
    "first_result.contents[1][1:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the explanation\n",
    "\n",
    "    Based upon what you've seen already, you might have figured out\n",
    "    that we have at least two options for how we extract the third \n",
    "    component of the record, which is the writer's explanation of why\n",
    "    the President's statement was a lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first option is to slice the contents attribute, like we did just now when extracting the lie\n",
    "\n",
    "first_result.contents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The second option is to search for the surrounding tag, like we did when extracting the date\n",
    "\n",
    "first_result.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was for an invasion before he was against it.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either way, we can access the text attribute and then slice off the opening and closing parentheses\n",
    "\n",
    "first_result.contents[2].text[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was for an invasion before he was against it.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Either way\n",
    "first_result.find('a').text[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the URL\n",
    "    Finally, we want to extract the URL of the article \n",
    "    that substantiates the writer's claim that the President was lying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    So far in this tutorial, we have been extracting text that is between tags. \n",
    "    In this case, the text we want to extract is located within the tag itself. \n",
    "    Specifically, we want to access the value of the href attribute within the <a> tag.\n",
    "\n",
    "    Beautiful Soup treats tag attributes and their values like key-value pairs in a dictionary: \n",
    "    you put the attribute name in brackets (like a dictionary key), and you get back the attribute's value:\n",
    "'''\n",
    "\n",
    "first_result.find('a')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Recap: Beautiful Soup methods and attributes\n",
    "    Before we finish building the dataset, let's summarize a few ways \n",
    "    you can interact with Beautiful Soup objects.\n",
    "\n",
    "You can apply these **two methods** to either the initial soup object or a Tag object (such as first_result):\n",
    "\n",
    "        .find(): searches for the first matching (html) tag, and returns a Tag object\n",
    "    \n",
    "        .find_all(): searches for all matching (html) tags, and returns a ResultSet object \n",
    "        (which you can treat like a list of Tags)\n",
    "    \n",
    "You can extract information from a Tag object (such as first_result) using these **two attributes**:\n",
    "\n",
    "        .text: extracts the text of a Tag, and returns a string\n",
    "    \n",
    "        .contents: extracts the children of a Tag, and returns a list of Tags and strings\n",
    "    \n",
    "    \n",
    "It's important to keep track of whether you are interacting with a Tag, ResultSet, list, or string, because that affects which methods and attributes you can access.\n",
    "\n",
    "And of course, there are many more methods and attributes available to you, which are described in the Beautiful Soup documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Building the dataset\n",
    "    Now that we've figured out how to extract the four components of first_result\n",
    "    (    \n",
    "         first_result.find('strong').text[0:-1] + ', 2017'\n",
    "         \n",
    "         first_result.contents[1][1:-2]\n",
    "         \n",
    "         first_result.find('a').text[1:-1]\n",
    "         \n",
    "         first_result.find('a')['href']  \n",
    "     )     \n",
    "    we can create a loop to repeat this process on all 180 results. We'll store the\n",
    "    output in a list of tuples called records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "              r                  [r,r,r,r,r,r,r...]\n",
    "   For each record   in all of   records in results:\n",
    "        \n",
    "        Give me these four components [date, lie, explanation, url] and put them into variables\n",
    "        \n",
    "        Now, append each one of them in a list of tuples\n",
    "'''\n",
    "\n",
    "\n",
    "records = []\n",
    "\n",
    "for result in results:\n",
    "    \n",
    "    date = result.find('strong').text[0:-1] + ', 2017'\n",
    "    lie = result.contents[1][1:-2]\n",
    "    explanation = result.find('a').text[1:-1]\n",
    "    url = result.find('a')['href']\n",
    "    \n",
    "    records.append((date, lie, explanation, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And as we did in the beginning:\n",
    "\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jan. 21, 2017',\n",
       "  \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\",\n",
       "  'He was for an invasion before he was against it.',\n",
       "  'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the'),\n",
       " ('Jan. 21, 2017',\n",
       "  'A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.',\n",
       "  'Trump was on the cover 11 times and Nixon appeared 55 times.',\n",
       "  'http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/'),\n",
       " ('Jan. 23, 2017',\n",
       "  'Between 3 million and 5 million illegal votes caused me to lose the popular vote.',\n",
       "  \"There's no evidence of illegal voting.\",\n",
       "  'https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Jan. 21, 2017', \"I wasn't a fan of Iraq. I didn't want to go into Iraq.\", 'He was for an invasion before he was against it.', 'https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the')\n",
      "\n",
      "\n",
      "\n",
      "('Jan. 21, 2017', 'A reporter for Time magazine — and I have been on their cover 14 or 15 times. I think we have the all-time record in the history of Time magazine.', 'Trump was on the cover 11 times and Nixon appeared 55 times.', 'http://nation.time.com/2013/11/06/10-things-you-didnt-know-about-time/')\n",
      "\n",
      "\n",
      "\n",
      "('Jan. 23, 2017', 'Between 3 million and 5 million illegal votes caused me to lose the popular vote.', \"There's no evidence of illegal voting.\", 'https://www.nytimes.com/2017/01/23/us/politics/donald-trump-congress-democrats.html')\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for content in records[0:3]:\n",
    "    print(content)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Applying a tabular data structure\n",
    "        The last major step in this process is to apply a tabular data structure \n",
    "        to our existing structure (which is a list of tuples). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lie</th>\n",
       "      <th>explanation</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan. 21, 2017</td>\n",
       "      <td>I wasn't a fan of Iraq. I didn't want to go in...</td>\n",
       "      <td>He was for an invasion before he was against it.</td>\n",
       "      <td>https://www.buzzfeed.com/andrewkaczynski/in-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan. 21, 2017</td>\n",
       "      <td>A reporter for Time magazine — and I have been...</td>\n",
       "      <td>Trump was on the cover 11 times and Nixon appe...</td>\n",
       "      <td>http://nation.time.com/2013/11/06/10-things-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan. 23, 2017</td>\n",
       "      <td>Between 3 million and 5 million illegal votes ...</td>\n",
       "      <td>There's no evidence of illegal voting.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/23/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan. 25, 2017</td>\n",
       "      <td>Now, the audience was the biggest ever. But th...</td>\n",
       "      <td>Official aerial photos show Obama's 2009 inaug...</td>\n",
       "      <td>https://www.nytimes.com/2017/01/21/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan. 25, 2017</td>\n",
       "      <td>Take a look at the Pew reports (which show vot...</td>\n",
       "      <td>The report never mentioned voter fraud.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/24/us/politics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                                lie  \\\n",
       "0  Jan. 21, 2017  I wasn't a fan of Iraq. I didn't want to go in...   \n",
       "1  Jan. 21, 2017  A reporter for Time magazine — and I have been...   \n",
       "2  Jan. 23, 2017  Between 3 million and 5 million illegal votes ...   \n",
       "3  Jan. 25, 2017  Now, the audience was the biggest ever. But th...   \n",
       "4  Jan. 25, 2017  Take a look at the Pew reports (which show vot...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0   He was for an invasion before he was against it.   \n",
       "1  Trump was on the cover 11 times and Nixon appe...   \n",
       "2             There's no evidence of illegal voting.   \n",
       "3  Official aerial photos show Obama's 2009 inaug...   \n",
       "4            The report never mentioned voter fraud.   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.buzzfeed.com/andrewkaczynski/in-20...  \n",
       "1  http://nation.time.com/2013/11/06/10-things-yo...  \n",
       "2  https://www.nytimes.com/2017/01/23/us/politics...  \n",
       "3  https://www.nytimes.com/2017/01/21/us/politics...  \n",
       "4  https://www.nytimes.com/2017/01/24/us/politics...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can convert our list of tuples into a DataFrame by passing it to the DataFrame constructor \n",
    "# and specifying the desired column names\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])\n",
    "\n",
    "# First 5 rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           object\n",
       "lie            object\n",
       "explanation    object\n",
       "url            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           datetime64[ns]\n",
       "lie                    object\n",
       "explanation            object\n",
       "url                    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's convert the date column from object to a datetime format\n",
    "\n",
    "df.date = pd.to_datetime(df.date)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lie</th>\n",
       "      <th>explanation</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>I wasn't a fan of Iraq. I didn't want to go in...</td>\n",
       "      <td>He was for an invasion before he was against it.</td>\n",
       "      <td>https://www.buzzfeed.com/andrewkaczynski/in-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>A reporter for Time magazine — and I have been...</td>\n",
       "      <td>Trump was on the cover 11 times and Nixon appe...</td>\n",
       "      <td>http://nation.time.com/2013/11/06/10-things-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>Between 3 million and 5 million illegal votes ...</td>\n",
       "      <td>There's no evidence of illegal voting.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/23/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>Now, the audience was the biggest ever. But th...</td>\n",
       "      <td>Official aerial photos show Obama's 2009 inaug...</td>\n",
       "      <td>https://www.nytimes.com/2017/01/21/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>Take a look at the Pew reports (which show vot...</td>\n",
       "      <td>The report never mentioned voter fraud.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/24/us/politics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                                lie  \\\n",
       "0 2017-01-21  I wasn't a fan of Iraq. I didn't want to go in...   \n",
       "1 2017-01-21  A reporter for Time magazine — and I have been...   \n",
       "2 2017-01-23  Between 3 million and 5 million illegal votes ...   \n",
       "3 2017-01-25  Now, the audience was the biggest ever. But th...   \n",
       "4 2017-01-25  Take a look at the Pew reports (which show vot...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0   He was for an invasion before he was against it.   \n",
       "1  Trump was on the cover 11 times and Nixon appe...   \n",
       "2             There's no evidence of illegal voting.   \n",
       "3  Official aerial photos show Obama's 2009 inaug...   \n",
       "4            The report never mentioned voter fraud.   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.buzzfeed.com/andrewkaczynski/in-20...  \n",
       "1  http://nation.time.com/2013/11/06/10-things-yo...  \n",
       "2  https://www.nytimes.com/2017/01/23/us/politics...  \n",
       "3  https://www.nytimes.com/2017/01/21/us/politics...  \n",
       "4  https://www.nytimes.com/2017/01/24/us/politics...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice how ['date'] columns is a little bit different from before\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the dataset to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trump_lies.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lie</th>\n",
       "      <th>explanation</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>I wasn't a fan of Iraq. I didn't want to go in...</td>\n",
       "      <td>He was for an invasion before he was against it.</td>\n",
       "      <td>https://www.buzzfeed.com/andrewkaczynski/in-20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-21</td>\n",
       "      <td>A reporter for Time magazine — and I have been...</td>\n",
       "      <td>Trump was on the cover 11 times and Nixon appe...</td>\n",
       "      <td>http://nation.time.com/2013/11/06/10-things-yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>Between 3 million and 5 million illegal votes ...</td>\n",
       "      <td>There's no evidence of illegal voting.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/23/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>Now, the audience was the biggest ever. But th...</td>\n",
       "      <td>Official aerial photos show Obama's 2009 inaug...</td>\n",
       "      <td>https://www.nytimes.com/2017/01/21/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>Take a look at the Pew reports (which show vot...</td>\n",
       "      <td>The report never mentioned voter fraud.</td>\n",
       "      <td>https://www.nytimes.com/2017/01/24/us/politics...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                                lie  \\\n",
       "0  2017-01-21  I wasn't a fan of Iraq. I didn't want to go in...   \n",
       "1  2017-01-21  A reporter for Time magazine — and I have been...   \n",
       "2  2017-01-23  Between 3 million and 5 million illegal votes ...   \n",
       "3  2017-01-25  Now, the audience was the biggest ever. But th...   \n",
       "4  2017-01-25  Take a look at the Pew reports (which show vot...   \n",
       "\n",
       "                                         explanation  \\\n",
       "0   He was for an invasion before he was against it.   \n",
       "1  Trump was on the cover 11 times and Nixon appe...   \n",
       "2             There's no evidence of illegal voting.   \n",
       "3  Official aerial photos show Obama's 2009 inaug...   \n",
       "4            The report never mentioned voter fraud.   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.buzzfeed.com/andrewkaczynski/in-20...  \n",
       "1  http://nation.time.com/2013/11/06/10-things-yo...  \n",
       "2  https://www.nytimes.com/2017/01/23/us/politics...  \n",
       "3  https://www.nytimes.com/2017/01/21/us/politics...  \n",
       "4  https://www.nytimes.com/2017/01/24/us/politics...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now you read it\n",
    "trump_lies = pd.read_csv('trump_lies.csv')\n",
    "\n",
    "trump_lies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: 16 lines of Python code\n",
    "    Here are the 16 lines of code that we used to scrape the web page, extract the relevant data,\n",
    "    convert it into a tabular dataset, and export it to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "results = soup.find_all('span', attrs={'class':'short-desc'})\n",
    "\n",
    "records = []\n",
    "for result in results:\n",
    "    date = result.find('strong').text[0:-1] + ', 2017'\n",
    "    lie = result.contents[1][1:-2]\n",
    "    explanation = result.find('a').text[1:-1]\n",
    "    url = result.find('a')['href']\n",
    "    records.append((date, lie, explanation, url))\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(records, columns=['date', 'lie', 'explanation', 'url'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.to_csv('trump_lies.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping Advice\n",
    "    Web scraping works best with static, well-structured web pages. \n",
    "    Dynamic or interactive content on a web page is often not accessible through the HTML source, \n",
    "    which makes scraping it much harder!\n",
    "    \n",
    "    Web scraping is a \"fragile\" approach for building a dataset.\n",
    "    The HTML on a page you are scraping can change at any time, which may cause your scraper to stop working.\n",
    "    \n",
    "    If you can download the data you need from a website, or if the website provides an API with data access,\n",
    "    those approaches are preferable to scraping since they are easier to implement and less likely to break.\n",
    "    \n",
    "    If you are scraping a lot of pages from the same website (in rapid succession),\n",
    "    it's best to insert delays in your code so that you don't overwhelm the website with requests.\n",
    "    If the website decides you are causing a problem, they can block your IP address\n",
    "    (which may affect everyone in your building!)\n",
    "    \n",
    "    Before scraping a website, you should review its robots.txt file\n",
    "    (also known as the Robots exclusion standard) to check whether you are \"allowed\" \n",
    "    to scrape their website. (Here is the robots.txt file for nytimes.com.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative syntax for Beautiful Soup\n",
    "    It's worth noting that Beautiful Soup actually offers multiple ways to express the same command.\n",
    "    For example, you can search for a tag by accessing it like an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<strong>Jan. 21 </strong>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search for a tag by name\n",
    "first_result.find('strong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<strong>Jan. 21 </strong>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shorter alternative: access it like an attribute\n",
    "first_result.strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also search for multiple tags a few different ways:\n",
    "# search for multiple tags by name and attribute\n",
    "\n",
    "results = soup.find_all('span', attrs={'class':'short-desc'})\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shorter alternative: if you don't specify a method, it's assumed to be find_all()\n",
    "results = soup('span', attrs={'class':'short-desc'})\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"short-desc\"><strong>Jan. 21 </strong>“I wasn't a fan of Iraq. I didn't want to go into Iraq.” <span class=\"short-truth\"><a href=\"https://www.buzzfeed.com/andrewkaczynski/in-2002-donald-trump-said-he-supported-invading-iraq-on-the\" target=\"_blank\">(He was for an invasion before he was against it.)</a></span></span>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# even shorter alternative: you can specify the attribute as if it's a parameter\n",
    "results = soup('span', class_='short-desc')\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful links:\n",
    "\n",
    "Web Scraping 101 with Python: http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/\n",
    "\n",
    "\n",
    "More web scraping with Python (and a map): http://www.gregreda.com/2013/04/29/more-web-scraping-with-python/\n",
    "\n",
    "\n",
    "Introduction to Web Scraping: https://stanford.edu/~vbauer/teaching/scraping.html\n",
    "\n",
    "\n",
    "Scrapy: https://scrapy.org/\n",
    "\n",
    "\n",
    "How a Math Genius Hacked OkCupid to Find True Love: https://www.wired.com/2014/01/how-to-hack-okcupid/\n",
    "\n",
    "\n",
    "How Netflix Reverse-Engineered Hollywood: https://www.theatlantic.com/technology/archive/2014/01/how-netflix-reverse-engineered-hollywood/282679/?single_page=true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
